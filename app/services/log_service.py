"""
å®æ—¶æ—¥å¿—æœåŠ¡
æ”¯æŒ SSE æµã€æ—¥å¿—è¿‡æ»¤å’Œå†å²è®°å½•
æ”¯æŒæ–‡ä»¶æ—¥å¿—æŒä¹…åŒ–ï¼ˆæ¯æ—¥è½®æ¢ï¼‰
"""

import asyncio
import os
import logging
import logging.handlers
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional, Set
from enum import Enum
import json
from collections import deque


class LogLevel(str, Enum):
    """æ—¥å¿—çº§åˆ«"""
    DEBUG = "debug"
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    SUCCESS = "success"


class LogType(str, Enum):
    """æ—¥å¿—ç±»å‹"""
    REQUEST = "request"        # HTTP è¯·æ±‚
    RESPONSE = "response"      # HTTP å“åº”
    EMAIL_GEN = "email_gen"    # ç”Ÿæˆé‚®ç®±
    EMAIL_FETCH = "email_fetch"  # è·å–é‚®ä»¶
    CODE_EXTRACT = "code_extract"  # æå–éªŒè¯ç 
    LLM_CALL = "llm_call"      # LLM è°ƒç”¨
    KV_ACCESS = "kv_access"    # Cloudflare KV è®¿é—®
    SYSTEM = "system"          # ç³»ç»Ÿäº‹ä»¶
    ERROR = "error"            # é”™è¯¯äº‹ä»¶


class LogEntry:
    """æ—¥å¿—æ¡ç›®"""
    def __init__(
        self,
        level: LogLevel,
        log_type: LogType,
        message: str,
        details: Optional[Dict] = None,
        duration_ms: Optional[float] = None
    ):
        self.timestamp = datetime.now()
        self.level = level
        self.log_type = log_type
        self.message = message
        self.details = details or {}
        self.duration_ms = duration_ms

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "timestamp": self.timestamp.isoformat(),
            "level": self.level.value,
            "type": self.log_type.value,
            "message": self.message,
            "details": self.details,
            "duration_ms": self.duration_ms,
        }

    def to_json(self) -> str:
        """è½¬æ¢ä¸º JSON"""
        return json.dumps(self.to_dict(), ensure_ascii=False)


class LogService:
    """æ—¥å¿—æœåŠ¡ï¼ˆå†…å­˜ + æ–‡ä»¶æŒä¹…åŒ–ï¼‰"""

    def __init__(self, max_history: int = 1000):
        self.max_history = max_history
        self.history: deque = deque(maxlen=max_history)
        self.subscribers: Set[asyncio.Queue] = set()
        self._lock = asyncio.Lock()
        # æŠ½æ ·è®¡æ•°å™¨ï¼ˆé™ä½ INFO/SUCCESS çº§åˆ«çš„ I/Oï¼‰
        self._info_counter = 0
        self._success_counter = 0
        
        # æ–‡ä»¶æ—¥èªŒé…ç½®
        self.file_logger: Optional[logging.Logger] = None
        self.json_logger: Optional[logging.Logger] = None
        self.log_dir: Optional[Path] = None
        self._setup_file_logging()

    def _setup_file_logging(self):
        """è®¾ç½®æ–‡ä»¶æ—¥å¿—ï¼ˆæ¯æ—¥è½®æ¢ï¼‰"""
        try:
            from app.config import settings
            
            if not settings.enable_file_logging:
                return
            
            # åˆ›å»ºæ—¥å¿—ç›®å½•
            self.log_dir = Path(settings.log_file_path)
            self.log_dir.mkdir(exist_ok=True)
            
            # åˆ›å»º TEXT loggerï¼ˆå¯é€‰ï¼‰
            self.file_logger = logging.getLogger("temp_email_service")
            self.file_logger.setLevel(logging.DEBUG)
            
            # ç§»é™¤å·²æœ‰çš„ handlersï¼ˆé¿å…é‡å¤ï¼‰
            self.file_logger.handlers.clear()
            
            if getattr(settings, "enable_text_file_logging", True):
                # åº”ç”¨æ—¥å¿—ï¼šæ¯æ—¥è½®æ¢ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
                app_log_file = self.log_dir / "app.log"
                app_handler = logging.handlers.TimedRotatingFileHandler(
                    filename=str(app_log_file),
                    when="midnight",
                    interval=1,
                    backupCount=settings.log_retention_days,
                    encoding="utf-8"
                )
                app_handler.setLevel(logging.DEBUG)

                # é”™è¯¯æ—¥å¿—ï¼šå•ç‹¬æ–‡ä»¶ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
                error_log_file = self.log_dir / "error.log"
                error_handler = logging.handlers.TimedRotatingFileHandler(
                    filename=str(error_log_file),
                    when="midnight",
                    interval=1,
                    backupCount=settings.log_retention_days,
                    encoding="utf-8"
                )
                error_handler.setLevel(logging.ERROR)

                text_formatter = logging.Formatter(
                    '[%(asctime)s] [%(levelname)s] [%(log_type)s] %(message)s | %(details)s',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
                app_handler.setFormatter(text_formatter)
                error_handler.setFormatter(text_formatter)

                self.file_logger.addHandler(app_handler)
                self.file_logger.addHandler(error_handler)

            # åˆ›å»º JSON loggerï¼ˆå¯é€‰ï¼›ä¾¿äº ELK/äº‘ç«¯æ—¥å¿—é‡‡é›†ï¼‰
            if getattr(settings, "enable_json_file_logging", True):
                self.json_logger = logging.getLogger("temp_email_service_json")
                self.json_logger.setLevel(logging.DEBUG)
                self.json_logger.handlers.clear()

                app_json_file = self.log_dir / "app.jsonl"
                app_json_handler = logging.handlers.TimedRotatingFileHandler(
                    filename=str(app_json_file),
                    when="midnight",
                    interval=1,
                    backupCount=settings.log_retention_days,
                    encoding="utf-8"
                )
                app_json_handler.setLevel(logging.DEBUG)

                error_json_file = self.log_dir / "error.jsonl"
                error_json_handler = logging.handlers.TimedRotatingFileHandler(
                    filename=str(error_json_file),
                    when="midnight",
                    interval=1,
                    backupCount=settings.log_retention_days,
                    encoding="utf-8"
                )
                error_json_handler.setLevel(logging.ERROR)

                json_formatter = logging.Formatter('%(message)s')
                app_json_handler.setFormatter(json_formatter)
                error_json_handler.setFormatter(json_formatter)

                self.json_logger.addHandler(app_json_handler)
                self.json_logger.addHandler(error_json_handler)
            
            print(f"ğŸ“ File logging enabled: {self.log_dir.absolute()}")
            
        except Exception as e:
            print(f"âŒ Failed to setup file logging: {e}")
            self.file_logger = None

    def _write_to_file(self, entry: LogEntry):
        """å†™å…¥æ—¥å¿—åˆ°æ–‡ä»¶ï¼ˆåŒæ­¥ï¼Œéé˜»å¡ï¼‰"""
        if not self.file_logger:
            return
        
        try:
            # è½¬æ¢çº§åˆ«
            level_map = {
                LogLevel.DEBUG: logging.DEBUG,
                LogLevel.INFO: logging.INFO,
                LogLevel.WARNING: logging.WARNING,
                LogLevel.ERROR: logging.ERROR,
                LogLevel.SUCCESS: logging.INFO,
            }

            log_level = level_map.get(entry.level, logging.INFO)

            # JSON å†…å®¹
            json_payload = entry.to_json()

            # æ–‡æœ¬æ ¼å¼ details
            details_str = json.dumps(entry.details, ensure_ascii=False) if entry.details else "{}"

            # TEXT handlersï¼ˆå¯é€‰ï¼‰
            if self.file_logger and self.file_logger.handlers:
                self.file_logger.log(
                    log_level,
                    entry.message,
                    extra={
                        'log_type': entry.log_type.value,
                        'details': details_str,
                        'duration_ms': entry.duration_ms or 0
                    }
                )

            # JSON handlersï¼ˆå¯é€‰ï¼‰
            if self.json_logger and self.json_logger.handlers:
                self.json_logger.log(log_level, json_payload)

        except Exception as e:
            # é¿å…æ—¥å¿—è®°å½•å¤±è´¥å½±å“ä¸»æµç¨‹
            print(f"âš ï¸ File logging error: {e}")

    def _should_sample(self, entry: "LogEntry") -> bool:
        """æ˜¯å¦éœ€è¦æŠ½æ ·ä¸¢å¼ƒæ­¤æ¡æ—¥å¿—ï¼ˆä»…é’ˆå¯¹ INFO/SUCCESSï¼‰"""
        try:
            from app.config import settings
        except Exception:
            return False

        if entry.level == LogLevel.INFO:
            rate = max(1, int(getattr(settings, "log_info_sample_rate", 1)))
            if rate > 1:
                self._info_counter = (self._info_counter + 1) % rate
                return self._info_counter != 0
        if entry.level == LogLevel.SUCCESS:
            rate = max(1, int(getattr(settings, "log_success_sample_rate", 1)))
            if rate > 1:
                self._success_counter = (self._success_counter + 1) % rate
                return self._success_counter != 0
        return False

    async def log(
        self,
        level: LogLevel,
        log_type: LogType,
        message: str,
        details: Optional[Dict] = None,
        duration_ms: Optional[float] = None
    ):
        """è®°å½•æ—¥å¿—ï¼ˆå†…å­˜ + æ–‡ä»¶ï¼‰"""
        entry = LogEntry(level, log_type, message, details, duration_ms)

        # æŠ½æ ·ï¼šåœ¨é«˜æµé‡æ—¶é™ä½ INFO/SUCCESS çš„ I/O ä¸å†…å­˜å ç”¨
        if self._should_sample(entry):
            return

        async with self._lock:
            # æ·»åŠ åˆ°å†…å­˜å†å²è®°å½•
            self.history.append(entry)

            # å†™å…¥æ–‡ä»¶ï¼ˆåœ¨é”å¤–æ‰§è¡Œï¼Œé¿å…é˜»å¡ï¼‰
            asyncio.create_task(asyncio.to_thread(self._write_to_file, entry))

            # å¹¿æ’­ç»™æ‰€æœ‰è®¢é˜…è€…
            dead_subscribers = set()
            for queue in self.subscribers:
                try:
                    await asyncio.wait_for(queue.put(entry), timeout=1.0)
                except (asyncio.TimeoutError, asyncio.QueueFull):
                    # è®¢é˜…è€…å¤„ç†è¿‡æ…¢ï¼Œæ ‡è®°ä¸ºç§»é™¤
                    dead_subscribers.add(queue)
                except Exception:
                    dead_subscribers.add(queue)

            # ç§»é™¤å¤±æ•ˆçš„è®¢é˜…è€…
            self.subscribers -= dead_subscribers

    async def subscribe(self) -> asyncio.Queue:
        """è®¢é˜…æ—¥å¿—æµ"""
        queue = asyncio.Queue(maxsize=100)
        async with self._lock:
            self.subscribers.add(queue)
        return queue

    async def unsubscribe(self, queue: asyncio.Queue):
        """å–æ¶ˆè®¢é˜…"""
        async with self._lock:
            self.subscribers.discard(queue)

    def get_history(
        self,
        levels: Optional[List[LogLevel]] = None,
        types: Optional[List[LogType]] = None,
        keyword: Optional[str] = None,
        limit: int = 100
    ) -> List[Dict]:
        """
        è·å–å†å²æ—¥å¿—ï¼ˆå¸¦è¿‡æ»¤ï¼‰

        Args:
            levels: è¿‡æ»¤çš„æ—¥å¿—çº§åˆ«åˆ—è¡¨
            types: è¿‡æ»¤çš„æ—¥å¿—ç±»å‹åˆ—è¡¨
            keyword: å…³é”®è¯æœç´¢ï¼ˆåœ¨ message å’Œ details ä¸­ï¼‰
            limit: æœ€å¤§è¿”å›æ•°é‡
        """
        filtered = []

        # ä»æœ€æ–°å¾€æ—§éå†
        for entry in reversed(self.history):
            # è¿‡æ»¤çº§åˆ«
            if levels and entry.level not in levels:
                continue

            # è¿‡æ»¤ç±»å‹
            if types and entry.log_type not in types:
                continue

            # è¿‡æ»¤å…³é”®è¯
            if keyword:
                keyword_lower = keyword.lower()
                if keyword_lower not in entry.message.lower():
                    # æ£€æŸ¥ details ä¸­æ˜¯å¦åŒ…å«å…³é”®è¯
                    details_str = json.dumps(entry.details, ensure_ascii=False).lower()
                    if keyword_lower not in details_str:
                        continue

            filtered.append(entry.to_dict())

            if len(filtered) >= limit:
                break

        return filtered

    def clear_history(self):
        """æ¸…ç©ºå†å²è®°å½•"""
        self.history.clear()

    async def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            async with self._lock:
                total = len(self.history)

                # ç»Ÿè®¡å„çº§åˆ«æ•°é‡
                level_counts = {}
                for level in LogLevel:
                    try:
                        level_counts[level.value] = sum(
                            1 for entry in self.history if entry.level == level
                        )
                    except Exception as e:
                        # å•ä¸ªçº§åˆ«ç»Ÿè®¡å¤±è´¥ï¼Œè®°å½•å¹¶ç»§ç»­
                        print(f"âš ï¸ ç»Ÿè®¡çº§åˆ« {level.value} å¤±è´¥: {e}")
                        level_counts[level.value] = 0

                # ç»Ÿè®¡å„ç±»å‹æ•°é‡
                type_counts = {}
                for log_type in LogType:
                    try:
                        type_counts[log_type.value] = sum(
                            1 for entry in self.history if entry.log_type == log_type
                        )
                    except Exception as e:
                        # å•ä¸ªç±»å‹ç»Ÿè®¡å¤±è´¥ï¼Œè®°å½•å¹¶ç»§ç»­
                        print(f"âš ï¸ ç»Ÿè®¡ç±»å‹ {log_type.value} å¤±è´¥: {e}")
                        type_counts[log_type.value] = 0

                # ç»Ÿè®¡ç‹¬ç«‹ IP æ•°é‡
                unique_ips = set()
                try:
                    for entry in self.history:
                        if entry.details and 'client_ip' in entry.details:
                            ip = entry.details['client_ip']
                            if ip and ip != 'unknown':
                                unique_ips.add(ip)
                except Exception as e:
                    # IP ç»Ÿè®¡å¤±è´¥ï¼Œè®°å½•ä½†è¿”å›ç©ºé›†åˆ
                    print(f"âš ï¸ ç»Ÿè®¡ç‹¬ç«‹ IP å¤±è´¥: {e}")
                    unique_ips = set()

                return {
                    "total": total,
                    "subscribers": len(self.subscribers),
                    "level_counts": level_counts,
                    "type_counts": type_counts,
                    "unique_ips": len(unique_ips),
                }
        except Exception as e:
            # æ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œè®°å½•è¯¦ç»†é”™è¯¯
            import traceback
            error_detail = traceback.format_exc()
            print(f"âŒ è·å–æ—¥å¿—ç»Ÿè®¡å¤±è´¥: {str(e)}")
            print(f"å®Œæ•´é”™è¯¯å †æ ˆ:\n{error_detail}")

            # è¿”å›ç©ºç»Ÿè®¡ï¼Œé¿å…æ•´ä½“æœåŠ¡å¤±è´¥
            return {
                "total": 0,
                "subscribers": 0,
                "level_counts": {},
                "type_counts": {},
                "unique_ips": 0,
                "error": str(e),
                "error_detail": error_detail
            }


# å…¨å±€å•ä¾‹
log_service = LogService()
