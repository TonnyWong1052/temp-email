#!/usr/bin/env python3
"""
Redis å£“åŠ›æ¸¬è©¦è…³æœ¬
æ¸¬è©¦é«˜ä½µç™¼ä¸‹çš„ Redis æ€§èƒ½å’Œå¿«å–æ•ˆæœ
"""
import asyncio
import time
from datetime import datetime
from typing import List, Dict
import statistics

import httpx


class RedisStressTest:
    """Redis å£“åŠ›æ¸¬è©¦"""

    def __init__(self, api_base: str = "http://localhost:1234", num_workers: int = 50):
        self.api_base = api_base
        self.num_workers = num_workers
        self.results: List[Dict] = []
        self.errors: List[str] = []

    async def generate_email(self, client: httpx.AsyncClient) -> Dict:
        """ç”Ÿæˆè‡¨æ™‚éƒµç®±"""
        try:
            start = time.time()
            response = await client.post(f"{self.api_base}/api/email/generate")
            duration = time.time() - start

            if response.status_code == 200:
                data = response.json()["data"]
                return {
                    "success": True,
                    "token": data["token"],
                    "address": data["address"],
                    "duration": duration
                }
            else:
                return {"success": False, "error": f"HTTP {response.status_code}", "duration": duration}

        except Exception as e:
            return {"success": False, "error": str(e), "duration": 0}

    async def fetch_mails(self, client: httpx.AsyncClient, token: str, use_cache: bool = False) -> Dict:
        """ç²å–éƒµä»¶åˆ—è¡¨"""
        try:
            # å¦‚æœè¦æ¸¬è©¦å¿«å–ï¼Œå…ˆè«‹æ±‚ä¸€æ¬¡
            if use_cache:
                await client.get(f"{self.api_base}/api/email/{token}/mails?limit=50")
                await asyncio.sleep(0.5)  # ç­‰å¾…å¿«å–å»ºç«‹

            start = time.time()
            response = await client.get(f"{self.api_base}/api/email/{token}/mails?limit=50")
            duration = time.time() - start

            if response.status_code == 200:
                data = response.json()
                mail_count = len(data.get("data", []))
                return {
                    "success": True,
                    "mail_count": mail_count,
                    "duration": duration,
                    "from_cache": use_cache
                }
            else:
                return {"success": False, "error": f"HTTP {response.status_code}", "duration": duration}

        except Exception as e:
            return {"success": False, "error": str(e), "duration": 0}

    async def worker_generate_emails(self, worker_id: int, num_requests: int) -> Dict:
        """å·¥ä½œåŸ·è¡Œç·’ï¼šç”Ÿæˆéƒµç®±"""
        results = {
            "worker_id": worker_id,
            "total": num_requests,
            "success": 0,
            "failed": 0,
            "durations": [],
            "errors": []
        }

        async with httpx.AsyncClient(timeout=30.0) as client:
            for i in range(num_requests):
                result = await self.generate_email(client)

                if result["success"]:
                    results["success"] += 1
                    results["durations"].append(result["duration"])
                else:
                    results["failed"] += 1
                    results["errors"].append(result.get("error", "Unknown"))

        return results

    async def worker_fetch_mails(self, worker_id: int, tokens: List[str], use_cache: bool = False) -> Dict:
        """å·¥ä½œåŸ·è¡Œç·’ï¼šç²å–éƒµä»¶"""
        results = {
            "worker_id": worker_id,
            "total": len(tokens),
            "success": 0,
            "failed": 0,
            "durations": [],
            "errors": [],
            "from_cache": use_cache
        }

        async with httpx.AsyncClient(timeout=30.0) as client:
            for token in tokens:
                result = await self.fetch_mails(client, token, use_cache)

                if result["success"]:
                    results["success"] += 1
                    results["durations"].append(result["duration"])
                else:
                    results["failed"] += 1
                    results["errors"].append(result.get("error", "Unknown"))

        return results

    async def test_concurrent_email_generation(self, requests_per_worker: int = 20):
        """æ¸¬è©¦ 1: ä½µç™¼ç”Ÿæˆéƒµç®±"""
        print("\n" + "="*80)
        print(f"æ¸¬è©¦ 1: ä½µç™¼ç”Ÿæˆéƒµç®± ({self.num_workers} å·¥ä½œåŸ·è¡Œç·’ x {requests_per_worker} è«‹æ±‚)")
        print("="*80)

        start_time = time.time()

        # å•Ÿå‹•æ‰€æœ‰å·¥ä½œåŸ·è¡Œç·’
        tasks = [
            self.worker_generate_emails(i, requests_per_worker)
            for i in range(self.num_workers)
        ]

        results = await asyncio.gather(*tasks)
        total_duration = time.time() - start_time

        # çµ±è¨ˆçµæœ
        total_success = sum(r["success"] for r in results)
        total_failed = sum(r["failed"] for r in results)
        all_durations = []
        for r in results:
            all_durations.extend(r["durations"])

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        if all_durations:
            avg_duration = statistics.mean(all_durations)
            median_duration = statistics.median(all_durations)
            min_duration = min(all_durations)
            max_duration = max(all_durations)
            p95_duration = sorted(all_durations)[int(len(all_durations) * 0.95)]
            p99_duration = sorted(all_durations)[int(len(all_durations) * 0.99)]
        else:
            avg_duration = median_duration = min_duration = max_duration = p95_duration = p99_duration = 0

        rps = total_success / total_duration if total_duration > 0 else 0

        # é¡¯ç¤ºçµæœ
        print(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
        print(f"   ç¸½è«‹æ±‚æ•¸: {total_success + total_failed}")
        print(f"   æˆåŠŸ: {total_success}")
        print(f"   å¤±æ•—: {total_failed}")
        print(f"   æˆåŠŸç‡: {total_success/(total_success + total_failed)*100:.1f}%")
        print(f"   ç¸½è€—æ™‚: {total_duration:.2f}s")
        print(f"   RPS (æ¯ç§’è«‹æ±‚æ•¸): {rps:.2f}")
        print(f"\nâ±ï¸  å›æ‡‰æ™‚é–“çµ±è¨ˆ:")
        print(f"   å¹³å‡å€¼: {avg_duration*1000:.2f}ms")
        print(f"   ä¸­ä½æ•¸: {median_duration*1000:.2f}ms")
        print(f"   æœ€å°å€¼: {min_duration*1000:.2f}ms")
        print(f"   æœ€å¤§å€¼: {max_duration*1000:.2f}ms")
        print(f"   P95: {p95_duration*1000:.2f}ms")
        print(f"   P99: {p99_duration*1000:.2f}ms")

        # æ”¶é›†æ‰€æœ‰æˆåŠŸçš„ token
        tokens = []
        for r in results:
            # é€™è£¡éœ€è¦ä¿®æ”¹ worker å‡½æ•¸ä¾†è¿”å› tokens
            pass

        return {
            "success": total_success,
            "failed": total_failed,
            "rps": rps,
            "avg_duration": avg_duration,
            "p95_duration": p95_duration
        }

    async def test_cache_performance(self):
        """æ¸¬è©¦ 2: å¿«å–æ€§èƒ½å°æ¯”"""
        print("\n" + "="*80)
        print("æ¸¬è©¦ 2: å¿«å–æ€§èƒ½å°æ¯” (å†·å¿«å– vs ç†±å¿«å–)")
        print("="*80)

        # å…ˆç”Ÿæˆä¸€å€‹éƒµç®±
        async with httpx.AsyncClient(timeout=30.0) as client:
            print("\nğŸ“§ ç”Ÿæˆæ¸¬è©¦éƒµç®±...")
            result = await self.generate_email(client)
            if not result["success"]:
                print("âŒ ç„¡æ³•ç”Ÿæˆæ¸¬è©¦éƒµç®±")
                return

            token = result["token"]
            print(f"âœ… æ¸¬è©¦éƒµç®±: {result['address']}")

            # æ¸¬è©¦å†·å¿«å– (ç¬¬ä¸€æ¬¡è«‹æ±‚)
            print("\nâ„ï¸  æ¸¬è©¦ 1: å†·å¿«å– (ç¬¬ä¸€æ¬¡è«‹æ±‚)")
            cold_durations = []
            for i in range(10):
                start = time.time()
                response = await client.get(f"{self.api_base}/api/email/{token}/mails?limit=50")
                duration = time.time() - start
                cold_durations.append(duration)
                await asyncio.sleep(0.1)

            cold_avg = statistics.mean(cold_durations)
            print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {cold_avg*1000:.2f}ms")
            print(f"   æœ€å°å€¼: {min(cold_durations)*1000:.2f}ms")
            print(f"   æœ€å¤§å€¼: {max(cold_durations)*1000:.2f}ms")

            # æ¸¬è©¦ç†±å¿«å– (å¾ŒçºŒè«‹æ±‚)
            print("\nğŸ”¥ æ¸¬è©¦ 2: ç†±å¿«å– (å¾ŒçºŒè«‹æ±‚)")
            await asyncio.sleep(1)  # ç­‰å¾…å¿«å–ç©©å®š
            hot_durations = []
            for i in range(10):
                start = time.time()
                response = await client.get(f"{self.api_base}/api/email/{token}/mails?limit=50")
                duration = time.time() - start
                hot_durations.append(duration)
                await asyncio.sleep(0.1)

            hot_avg = statistics.mean(hot_durations)
            print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {hot_avg*1000:.2f}ms")
            print(f"   æœ€å°å€¼: {min(hot_durations)*1000:.2f}ms")
            print(f"   æœ€å¤§å€¼: {max(hot_durations)*1000:.2f}ms")

            # è¨ˆç®—åŠ é€Ÿæ¯”
            speedup = cold_avg / hot_avg if hot_avg > 0 else 0
            improvement = ((cold_avg - hot_avg) / cold_avg * 100) if cold_avg > 0 else 0

            print(f"\nğŸ“Š å¿«å–æ•ˆæœ:")
            print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
            print(f"   æ€§èƒ½æå‡: {improvement:.1f}%")

            if speedup > 1.5:
                print("   âœ… å¿«å–æ•ˆæœé¡¯è‘—")
            elif speedup > 1.1:
                print("   âš ï¸  å¿«å–æ•ˆæœä¸€èˆ¬")
            else:
                print("   âŒ å¿«å–å¯èƒ½æœªç”Ÿæ•ˆ")

        return {
            "cold_avg": cold_avg,
            "hot_avg": hot_avg,
            "speedup": speedup,
            "improvement": improvement
        }

    async def test_concurrent_reads(self, num_emails: int = 10, concurrent_per_email: int = 10):
        """æ¸¬è©¦ 3: ä½µç™¼è®€å– (æ¸¬è©¦è«‹æ±‚åˆä½µ)"""
        print("\n" + "="*80)
        print(f"æ¸¬è©¦ 3: ä½µç™¼è®€å– ({num_emails} å€‹éƒµç®± x {concurrent_per_email} ä½µç™¼è«‹æ±‚)")
        print("="*80)

        # ç”Ÿæˆæ¸¬è©¦éƒµç®±
        print(f"\nğŸ“§ ç”Ÿæˆ {num_emails} å€‹æ¸¬è©¦éƒµç®±...")
        tokens = []
        async with httpx.AsyncClient(timeout=30.0) as client:
            for i in range(num_emails):
                result = await self.generate_email(client)
                if result["success"]:
                    tokens.append(result["token"])

        print(f"âœ… å·²ç”Ÿæˆ {len(tokens)} å€‹æ¸¬è©¦éƒµç®±")

        # å°æ¯å€‹éƒµç®±ç™¼èµ·ä½µç™¼è«‹æ±‚
        print(f"\nğŸš€ å°æ¯å€‹éƒµç®±ç™¼èµ· {concurrent_per_email} å€‹ä½µç™¼è«‹æ±‚...")
        start_time = time.time()
        async with httpx.AsyncClient(timeout=30.0) as client:
            all_tasks = []
            for token in tokens:
                for _ in range(concurrent_per_email):
                    task = self.fetch_mails(client, token, use_cache=False)
                    all_tasks.append(task)
            # ç¢ºä¿åœ¨é—œé–‰ client ä¹‹å‰ç­‰å¾…æ‰€æœ‰è«‹æ±‚å®Œæˆ
            results = await asyncio.gather(*all_tasks, return_exceptions=True)
        total_duration = time.time() - start_time

        # çµ±è¨ˆçµæœ
        # å¿½ç•¥ç•°å¸¸ï¼Œåƒ…çµ±è¨ˆæˆåŠŸ/å¤±æ•—
        normalized = [r for r in results if isinstance(r, dict)]
        success_count = sum(1 for r in normalized if r.get("success"))
        failed_count = sum(1 for r in normalized if not r.get("success"))
        durations = [r["duration"] for r in normalized if r.get("success")]

        if durations:
            avg_duration = statistics.mean(durations)
            p95_duration = sorted(durations)[int(len(durations) * 0.95)]
        else:
            avg_duration = p95_duration = 0

        rps = success_count / total_duration if total_duration > 0 else 0

        print(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
        print(f"   ç¸½è«‹æ±‚æ•¸: {len(results)}")
        print(f"   æˆåŠŸ: {success_count}")
        print(f"   å¤±æ•—: {failed_count}")
        print(f"   æˆåŠŸç‡: {success_count/len(results)*100:.1f}%")
        print(f"   ç¸½è€—æ™‚: {total_duration:.2f}s")
        print(f"   RPS: {rps:.2f}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {avg_duration*1000:.2f}ms")
        print(f"   P95 å›æ‡‰æ™‚é–“: {p95_duration*1000:.2f}ms")

        return {
            "success": success_count,
            "failed": failed_count,
            "rps": rps,
            "avg_duration": avg_duration,
            "p95_duration": p95_duration
        }

    async def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("="*80)
        print("Redis å£“åŠ›æ¸¬è©¦")
        print("="*80)
        print(f"API Base: {self.api_base}")
        print(f"å·¥ä½œåŸ·è¡Œç·’æ•¸: {self.num_workers}")
        print(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)

        # æ¸¬è©¦ 1: ä½µç™¼ç”Ÿæˆéƒµç®±
        test1_result = await self.test_concurrent_email_generation(requests_per_worker=20)

        # æ¸¬è©¦ 2: å¿«å–æ€§èƒ½å°æ¯”
        test2_result = await self.test_cache_performance()

        # æ¸¬è©¦ 3: ä½µç™¼è®€å–
        test3_result = await self.test_concurrent_reads(num_emails=10, concurrent_per_email=10)

        # ç¸½çµ
        print("\n" + "="*80)
        print("æ¸¬è©¦ç¸½çµ")
        print("="*80)
        print(f"\nğŸ“§ æ¸¬è©¦ 1 - ä½µç™¼ç”Ÿæˆéƒµç®±:")
        print(f"   æˆåŠŸç‡: {test1_result['success']/(test1_result['success'] + test1_result['failed'])*100:.1f}%")
        print(f"   RPS: {test1_result['rps']:.2f}")
        print(f"   å¹³å‡å›æ‡‰æ™‚é–“: {test1_result['avg_duration']*1000:.2f}ms")

        print(f"\nğŸ”¥ æ¸¬è©¦ 2 - å¿«å–æ€§èƒ½:")
        print(f"   åŠ é€Ÿæ¯”: {test2_result['speedup']:.2f}x")
        print(f"   æ€§èƒ½æå‡: {test2_result['improvement']:.1f}%")

        print(f"\nğŸš€ æ¸¬è©¦ 3 - ä½µç™¼è®€å–:")
        print(f"   æˆåŠŸç‡: {test3_result['success']/(test3_result['success'] + test3_result['failed'])*100:.1f}%")
        print(f"   RPS: {test3_result['rps']:.2f}")
        print(f"   P95 å›æ‡‰æ™‚é–“: {test3_result['p95_duration']*1000:.2f}ms")

        print("\n" + "="*80)
        print(f"çµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)


async def main():
    """ä¸»å‡½æ•¸"""
    import sys

    api_base = sys.argv[1] if len(sys.argv) > 1 else "http://localhost:1234"
    num_workers = int(sys.argv[2]) if len(sys.argv) > 2 else 50

    tester = RedisStressTest(api_base=api_base, num_workers=num_workers)
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())
